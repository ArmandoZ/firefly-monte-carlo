%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Jacobs Landscape Poster
% LaTeX Template
% Version 1.1 (14/06/14)
%
% Created by:
% Computational Physics and Biophysics Group, Jacobs University
% https://teamwork.jacobs-university.de:8443/confluence/display/CoPandBiG/LaTeX+Poster
%
% Further modified by:
% Nathaniel Johnston (nathaniel@njohnston.ca)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[final]{beamer}

\usepackage[scale=1.24]{beamerposter} % Use the beamerposter package for laying out the poster
\usepackage{subfigure}
\usepackage{hyperref}

\usetheme{confposter} % Use the confposter theme supplied with this template

\setbeamercolor{block title}{fg=ngreen,bg=white} % Colors of the block titles
\setbeamercolor{block body}{fg=black,bg=white} % Colors of the body of blocks
\setbeamercolor{block alerted title}{fg=white,bg=dblue!70} % Colors of the highlighted block titles
\setbeamercolor{block alerted body}{fg=black,bg=dblue!10} % Colors of the body of highlighted blocks
% Many more colors are available for use in beamerthemeconfposter.sty

%-----------------------------------------------------------
% Define the column widths and overall poster size
% To set effective sepwid, onecolwid and twocolwid values, first choose how many columns you want and how much separation you want between columns
% In this template, the separation width chosen is 0.024 of the paper width and a 4-column layout
% onecolwid should therefore be (1-(# of columns+1)*sepwid)/# of columns e.g. (1-(4+1)*0.024)/4 = 0.22
% Set twocolwid to be (2*onecolwid)+sepwid = 0.464
% Set threecolwid to be (3*onecolwid)+2*sepwid = 0.708

\newlength{\sepwid}
\newlength{\onecolwid}
\newlength{\twocolwid}
\newlength{\threecolwid}
\setlength{\paperwidth}{48in} % A0 width: 46.8in
\setlength{\paperheight}{36in} % A0 height: 33.1in
\setlength{\sepwid}{0.024\paperwidth} % Separation width (white space) between columns
\setlength{\onecolwid}{0.22\paperwidth} % Width of one column
\setlength{\twocolwid}{0.464\paperwidth} % Width of two columns
\setlength{\threecolwid}{0.708\paperwidth} % Width of three columns
\setlength{\topmargin}{-0.5in} % Reduce the top margin size
%-----------------------------------------------------------

\usepackage{graphicx}  % Required for including images

\usepackage{booktabs} % Top and bottom rules for tables

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{Firefly Monte Carlo: Exact MC with data subsets} % Poster title

\author{Feynman Liang, Max Chamberlin, Kai Xu} % Author(s)

\institute{Cambridge University Engineering Department} % Institution(s)

%----------------------------------------------------------------------------------------

\begin{document}

\addtobeamertemplate{block end}{}{\vspace*{2ex}} % White space under blocks
\addtobeamertemplate{block alerted end}{}{\vspace*{2ex}} % White space under highlighted (alert) blocks

\setlength{\belowcaptionskip}{2ex} % White space under figures
\setlength\belowdisplayshortskip{2ex} % White space under equations

\begin{frame}[t] % The whole poster is enclosed in one beamer frame

\begin{columns}[t] % The whole poster consists of three major columns, the second of which is split into two columns twice - the [t] option aligns each column's content to the top

\begin{column}{\sepwid}\end{column} % Empty spacer column

\begin{column}{\onecolwid} % The first column

%----------------------------------------------------------------------------------------
%	OBJECTIVES
%----------------------------------------------------------------------------------------

\begin{alertblock}{Objectives}

FlyMC is concerned with estimating a large data-set's likelihood from smaller subsets.
After assuming the existence of a lower bound $0 <
  B_n(\theta) \leq L_n(\theta) = P(x_n | \theta)$ on the likelihood, it:
\begin{itemize}
  \item Presents an auxillary variable method allowing estimation of the full dataset's likelihood
    using only subsets of the data
  \item Discusses additional aspects such as \emph{MAP tuning} (tuning
    the $B_n(\theta)$ bound to be tight at a MAP estimate for $\theta$),
    \emph{implicit sampling} (running a second MC to indirectly sample the auxillary
    variables), and strategies for selecting $B_n(\theta)$
  \item Scales to large data-sets which do not fit on a single machine
  \item Is general purpose and applicable to a variety of methods, including:
    logistic regression, softmax classification, and robust linear regression
\end{itemize}

\end{alertblock}

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

\begin{block}{Background}

A central quantity of interest when performing inference is the likelihood of
iid data $X = \{x_i\}_{i=1}^N$ under some parametric probability model with
parameters $\theta$:
\begin{equation}
  \label{eq:lik}
  L(\theta) = \prod_{i=1}^N L_n(\theta) = \prod_{i=1}^N P(x_i | \theta)
\end{equation}

For example, these likelihoods must be computed  when sampling a posterior
distibution $P(\theta | X)$ using  Metroplis-Hastings MCMC, where
we must compute the acceptance probability:
\begin{align}
  A(\theta'| \theta)
  &= \min \left\{
      1,
      \frac{q(\theta | \theta') P(\theta'|X)}{q(\theta' | \theta) P(\theta | X)}
    \right\}\\
  &= \min \left\{
      1,
      \frac{q(\theta|\theta') L(\theta')P(\theta')}{q(\theta'|\theta) L(\theta)P(\theta)}
    \right\}
\end{align}
where the proposal distribution $q(\theta|\theta')$ is the transition
kernel for a reversible Markov chain.

Unfortunately, in the era of 'Big Data' $N$ may be on the order of millions of
bytes and computing $L(\theta)$ at every iteration of the MC may be
prohibitively slow. Ultimately, the aim of Firefly Monte Carlo is to speed up
such MCMC methods, by ensuring that we do not recompute likelihods for all
data-points at each iteration but instead only over a smaller tractable
subset. 

\end{block}

%----------------------------------------------------------------------------------------

\end{column} % End of the first column

\begin{column}{\sepwid}\end{column} % Empty spacer column

\begin{column}{\twocolwid} % Begin a column which is two columns wide (column 2)

\begin{columns}[t,totalwidth=\twocolwid] % Split up the two columns wide column

\begin{column}{\onecolwid}\vspace{-.6in} % The first column within column 2 (column 2.1)

%----------------------------------------------------------------------------------------
%	MATERIALS
%----------------------------------------------------------------------------------------

\begin{block}{Theory}

% TODO: discuss how FlyMC is ``exact'', augmenting joint does not change marginal
An auxillary variable method works by introducing auxillary variables $Z$
to form the joint distribution $P(X,Z|\theta) = P(Z|X,\theta) L(\theta)$,
then later marginalizing to yield $L(\theta) = \sum_Z P(X,Z|\theta)$.

In FlyMC, the auxillary \emph{brightness} variables $z_i$ are Bernoulli
\begin{equation}
  \label{eq:brightness}
  P(z_n | x_n, \theta)
  = \left(
  \frac{L_n(\theta) - B_n(\theta)}{L_n(\theta)}
  \right)^{z_n} \left(
  \frac{B_n(\theta)}{L_n(\theta)}
  \right)^{1-z_n}
\end{equation}
where \textbf{the existence of a lower bound $0 < B_n(\theta) \leq L_n(\theta)$ on
the likelihood is assumed}. The joint distribution then has the form
\begin{align}
  \label{eq:complete-lik}
  P(x_n,z_n|\theta) = \begin{cases}
    L_n(\theta) - B_n(\theta) & z_n = 1\\
    B_n(\theta) & \text{otherwise}
  \end{cases}
\end{align}
% TODO: interpret z_i as blinking fireflies
A key observation is that Equation~\ref{eq:complete-lik} \textbf{only
requires computation of $L_n(\theta)$ for the \emph{bright} points $\{x_n \in
X : z_n = 1\}$}. Similarly defining the \emph{dim} points $X \setminus
bright$ allows us to decompose
\begin{align}
  \label{eq:complete-lik-all-data}
  P(X,Z|\theta)
  &= \prod_{n=1}^N (L_n(\theta) - B_n(\theta))^{z_n} (B_n(\theta))^{1 - z_n} \\
  &= \prod_{n \in bright} (L_n(\theta) - B_n(\theta)) \prod_{n \in dim} B_n(\theta)
\end{align}

If $B_n(\theta)$ is chosen (e.g.\ exponential family) such that $\prod_{n \in
dim} B_n(\theta)$ is $O(1)$, then a $O(\frac{E[\# bright]}{N})$ speedup can
be attained.

%TODO: discuss how to choose B_N, tightness at MAP estimate

\end{block}

\begin{block}{Algorithm}

\begin{enumerate}
  \item Initalize $\theta^{(0)}$.
  \item Sample $z^{(t)}_n \sim \text{Bernoulli}\left(
    \frac{L_n(\theta^{(t)}) - B_n(\theta^{(t)})}{L_n(\theta^{(t)})}
    \right)$
  \item Propose $\theta^{(t+1)} \sim q(\theta^{(t)} \to \theta^{(t+1)})$.
  \item Compute acceptance probability $A(\theta^{(t)} \to \theta^{(t+1})$
    with $z^{(t)}_n$ fixed and accept with probability $A(\theta^{(t)} \to \theta^{(t+1})$
\end{enumerate}

Many $z_n = 0$ so it is wasteful to directly sample the brightness variables
$z$. another MH MCMC to efficiently sample $z_n$ from
Equation~\ref{eq:brightness}. This yields \emph{implicit sampling} and
introduces an additional parameter $q_{dim \to bright}$ used as the proposal
probabilities for the brightness MC.

\end{block}

\end{column} % End of column 2.1

\begin{column}{\onecolwid}\vspace{-.6in} % The second column within column 2 (column 2.2)

\begin{block}{Logistic Regression}

We demonstrate FlyMC fitting logistic regression with prior
$P(\theta) \sim \mathcal{N}(0,I)$ to classify $7$s and $9$s on MNIST.
Figure~\ref{fig:evals} shows FlyMC requires more than 100 orders of magnitude
less likelihood evaluations to find similarly probable posterior modes:

\begin{figure}
  \centering
  \hspace{1.3cm}\includegraphics[width=0.8\linewidth]{Figures/evals_per_iter.png}
  \newline
  \includegraphics[width=0.8\linewidth]{Figures/evals_per_iter.png}
  \caption{FlyMC explores similar posterior modes while requiring much less likelihood evaluations}
  \label{fig:evals}
\end{figure}

Figure~\ref{fig:traces} shows $\theta$ traces from a represenative run. Note that
the values of $\theta$ vary less under FlyMAP, suggesting that mixing is slower
using FlyMAP's estimates over only $bright$ datapoints, which is further
verified by Figure~\ref{fig:acf}.

\begin{figure}
  \begin{center}
    \includegraphics[width=0.5\linewidth]{Figures/trace_mcmc.png}
    \includegraphics[width=0.5\linewidth]{Figures/trace_flymap.png}
  \end{center}
  \caption{Traces of $\theta$ for regular MH-MCMC (\emph{top}) and MAP-tuned
  FlyMC (\emph{bottom})}
  \label{fig:traces}
\end{figure}

\end{block}

\end{column} % End of column 2.2

\end{columns} % End of the split of column 2 - any content after this will now take up 2 columns width

\end{column} % End of the second column

\begin{column}{\sepwid}\end{column} % Empty spacer column

\begin{column}{\onecolwid} % The third column

\begin{figure}
  \includegraphics[width=0.8\linewidth]{Figures/acf_logistic.png}
  \caption{Autocorrelation of logistic regression samples}
  \label{fig:acf}
\end{figure}

\begin{block}{Softmax}

To demonstrate applicability to other applications and methods, we
apply FlyMC to fit a softmax classification model on three CIFAR-10
classes (airplane, automobile and bird) using Langevin
dynamics. Figure~\ref{fig:softmax} reports similar findings as
previously reported.

\begin{figure}
  \includegraphics[width=0.5\linewidth]{Figures/log_lik_softmax.png}
  \includegraphics[width=0.5\linewidth]{Figures/nlp_softmax.png}
  \caption{Softmax classification on CIFAR-10 fitted using Metropolis-adjusted Langevin dynamics}
  \label{fig:softmax}
\end{figure}

\end{block}


%----------------------------------------------------------------------------------------
%	CONCLUSION
%----------------------------------------------------------------------------------------

\begin{block}{Conclusion}

\begin{enumerate}
  \item Investigation of how to choose $B_n$ such that $\prod_n B_n$ easy
  \item MAP estimation to optimize $B_n$ doesn't work when $N$ is large
  \item Implement on software platforms supporting large-scale data
\end{enumerate}

\end{block}


\end{column} % End of the third column

\end{columns} % End of all the columns in the poster

\end{frame} % End of the enclosing frame

\end{document}
